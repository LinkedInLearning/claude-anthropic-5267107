{"cells":[{"cell_type":"markdown","metadata":{"id":"LrAzwgaBqhh7"},"source":["<h2 style=\"text-align: center; background-color: #4d648d; font-family:Arial; color: white; padding: 13px; line-height: 1; border-radius:10px\"> 03_06 Utiliser les instructions système</h2>"]},{"cell_type":"markdown","metadata":{"id":"48u2zL8Oqhh_"},"source":["# Mise en pratique"]},{"cell_type":"code","source":["!pip install anthropic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0FCXg11VO5e","executionInfo":{"status":"ok","timestamp":1749667575006,"user_tz":-120,"elapsed":13023,"user":{"displayName":"Alison Patou","userId":"17966795866743930044"}},"outputId":"8a1c2a21-2540-43b5-eee3-7feacb200d8a","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting anthropic\n","  Downloading anthropic-0.54.0-py3-none-any.whl.metadata (25 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.11.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.14.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.1)\n","Downloading anthropic-0.54.0-py3-none-any.whl (288 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: anthropic\n","Successfully installed anthropic-0.54.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3I82bN7Rqhh_"},"outputs":[],"source":["import anthropic\n","import os"]},{"cell_type":"code","source":["# Récupère la liste des modèles accessibles\n","def lister_modeles_disponibles():\n","    modeles = client.models.list()\n","    print(\"Modèles disponibles avec votre clé API :\")\n","    for m in modeles:\n","        print(\"→\", m.id)\n","\n","# Exécuter la fonction\n","lister_modeles_disponibles()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g95nvEX0LtYp","executionInfo":{"status":"ok","timestamp":1749665376561,"user_tz":-120,"elapsed":143,"user":{"displayName":"Alison Patou","userId":"17966795866743930044"}},"outputId":"5b9fca39-7ec6-4715-e4db-cc6227adb384"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Modèles disponibles avec votre clé API :\n","→ claude-opus-4-20250514\n","→ claude-sonnet-4-20250514\n","→ claude-3-7-sonnet-20250219\n","→ claude-3-5-sonnet-20241022\n","→ claude-3-5-haiku-20241022\n","→ claude-3-5-sonnet-20240620\n","→ claude-3-haiku-20240307\n","→ claude-3-opus-20240229\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6216,"status":"ok","timestamp":1749667644332,"user":{"displayName":"Alison Patou","userId":"17966795866743930044"},"user_tz":-120},"id":"F_21d97EqhiB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"40caef1e-f1b1-4745-97d0-3b53acca4a0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","------------- Réponse orientée -------------\n","\n","Bien sûr, je vais vous expliquer le principe des transformers de manière pédagogique et structurée.\n","\n","Les transformers sont une architecture de réseau de neurones profonds qui a révolutionné de nombreux domaines du traitement du langage naturel (NLP) et de l'apprentissage automatique en général. Voici les points clés à retenir :\n","\n","1. Attention mécanisme clé :\n","   - Contrairement aux modèles de type RNN (Recurrent Neural Network) qui traitent les données de manière séquentielle, les transformers se basent sur un mécanisme d'attention.\n","   - Ce mécanisme d'attention permet au modèle de se concentrer sur les parties les plus pertinentes des données d'entrée, sans avoir besoin de parcourir séquentiellement toute l'information.\n","\n","2. Encodeur-décodeur :\n","   - Les transformers sont généralement composés de deux parties principales : un encodeur et un décodeur.\n","   - L'encodeur prend les données d'entrée (par exemple, une phrase) et les transforme en une représentation interne (vecteurs de caractéristiques).\n","   - Le décodeur utilise cette représentation pour générer la sortie souhaitée (par exemple, une traduction ou une réponse à une question).\n","\n","3. Multi-tête d'attention :\n","   - Une innovation clé des transformers est l'utilisation de plusieurs têtes d'attention en parallèle.\n","   - Chaque tête d'attention se concentre sur des aspects différents des données d'entrée, permettant ainsi une compréhension plus riche et nuancée.\n","\n","4. Connexions résiduelles et normalisation :\n","   - Les transformers utilisent des connexions résiduelles et des techniques de normalisation des couches, ce qui facilite l'entraînement de modèles très profonds.\n","   - Cela permet d'éviter les problèmes de dégradation du gradient et d'améliorer les performances globales du modèle.\n","\n","5. Parallélisation et efficacité :\n","   - Grâce à leur architecture basée sur l'attention plutôt que sur le traitement séquentiel, les transformers peuvent être entraînés et utilisés de manière beaucoup plus efficace et parallélisée sur du matériel informatique moderne.\n","   - Cela les rend particulièrement adaptés aux tâches nécessitant un traitement rapide de grandes quantités de données, comme la traduction automatique ou la génération de texte.\n","\n","En résumé, les transformers représentent une avancée majeure dans l'architecture des réseaux de neurones profonds, en particulier pour les tâches de traitement du langage naturel. Leur mécanisme d'attention, leur structure encodeur-décodeur et leur parallélisation efficace en font des modèles très pu\n"]}],"source":["ANTHROPIC_API_KEY = \"XXXXXX\"\n","\n","client = anthropic.Anthropic(\n","    api_key=ANTHROPIC_API_KEY\n",")\n","\n","def utiliser_instruction_systeme(system_prompt, question):\n","    \"\"\"Utilise un prompt système pour orienter Claude.\"\"\"\n","    response = client.messages.create(\n","        model=\"claude-3-haiku-20240307\",  # ou autre modèle selon vos accès\n","        max_tokens=700,\n","        temperature=0.5,\n","        system=system_prompt,\n","        messages=[{\"role\": \"user\", \"content\": question}]\n","    )\n","    return response.content[0].text.strip()\n","\n","# Exemple 1 : Claude joue un formateur\n","instruction = \"Tu es un formateur en IA. Explique les choses de façon pédagogique et structurée.\"\n","question = \"Peux-tu expliquer le principe de transformers ?\"\n","\n","reponse = utiliser_instruction_systeme(instruction, question)\n","\n","print(\"\\n------------- Réponse orientée -------------\\n\")\n","print(reponse)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}